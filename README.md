# ğŸ§  ChibiRan: Your Mini AI Assistant

## RAG-based QA for Scientific PDFs

> **Version 1.0** 

This is a modular **Retrieval-Augmented Generation (RAG)** assistant built with **LangChain**, **FAISS/Chroma**, and **OpenAI/Hugging Face** LLMs.

Upload a research PDF, ask natural questions, and get intelligent answers â€” powered by vector embeddings, semantic search, and LLMs.

---

## ğŸš€ Live App

[![Hugging Face](https://img.shields.io/badge/ğŸ¤—%20Try%20on-Hugging%20Face-blue?logo=huggingface)](https://huggingface.co/spaces/GazalRan/ChibiRan)

---

## ğŸ“¸ Screenshot

<img src="static/gradio-interface.png" alt="Gradio Interface" width="100%">

---

## ğŸ”§ Key Features

- ğŸ“„ Upload and parse any scientific PDF
- ğŸ§  Question-answering powered by `gpt-4`, Mistral, or your own model
- âœ‚ï¸ Automatic chunking and embedding with LangChain
- ğŸ” Search via **FAISS** (default) or **ChromaDB**
- ğŸ¯ Two-layer QA: strict context-only answers + fallback summarization
- ğŸ’¾ Caches vectorstores â€” avoids re-embedding
- ğŸ” GPT password-lock for usage control (e.g., token cost management)
- ğŸ§ª Dev mode for cost-free testing
- ğŸŒ Gradio interface for local or cloud deployment

---

## ğŸ’¼ Tech Stack / Skills

- **Python**, **LangChain**, **LLMs**, **RAG**
- OpenAI API, Hugging Face Hub models
- FAISS, ChromaDB, PyPDFLoader
- Gradio UI, `.env` & Hugging Face secrets
- Ready for local or cloud (Hugging Face Spaces, Streamlit)

---

## ğŸ“ Project Structure

```
rag-ai-assistant/
â”œâ”€â”€ app_local.py           # Gradio app (local)
â”œâ”€â”€ app_hg.py              # Gradio app (Hugging Face Deployment)
â”œâ”€â”€ main.py                # Optional CLI runner
â”œâ”€â”€ config.py              # Central config (model, chunk size, secrets)
â”œâ”€â”€ loader.py              # Vectorstore loading (FAISS or Chroma)
â”œâ”€â”€ llm_provider.py        # Dynamically load OpenAI or Hugging Face LLMs
â”œâ”€â”€ utils.py               # Prompting logic + fallback handling
â”œâ”€â”€ documents/             # Upload PDFs here
â”œâ”€â”€ faiss_dbs/             # FAISS vectorstore cache
â”œâ”€â”€ chroma_dbs/            # Chroma vectorstore cache
â””â”€â”€ static/                # Avatar, screenshots
```

---

## ğŸ› ï¸ Setup Instructions

### 1. Clone and Create Environment

```bash
git clone https://github.com/ghazalehran/rag-ai-assistant.git
cd rag-ai-assistant
python -m venv rag-env
source rag-env/bin/activate  # Windows: rag-env\Scripts\activate
pip install -r requirements.txt
```

### 2. Add Secrets Locally

Create a `.env` file:

```
OPENAI_API_KEY=sk-...
HUGGINGFACEHUB_API_TOKEN=hf-...
GPT_ACCESS_PASSWORD=your-password
```

> For Hugging Face Spaces or Streamlit: use **secret management UI** instead.

---

## ğŸ–¥ Run the App Locally

```bash
python app_local.py
```

Then visit `http://localhost:7860` in your browser.

---

## âš™ï¸ Configuration Options

All in `config.py`:

| Key                  | Description                          |
|----------------------|--------------------------------------|
| `LLM_BACKEND`        | `"openai"` / `"huggingface"`         |
| `VECTORSTORE_BACKEND`| `"faiss"` / `"chroma"`               |
| `TEMPERATURE`        | Controls LLM creativity              |
| `USE_HF_SECRETS`     | Use `.env` (False) or cloud secrets  |
| `OPENAI_MODEL`       | Default: `"gpt-4"`                   |
| `HF_MODEL`           | Mistral, Falcon, etc.                |

---

## âœ… Models Used

- **OpenAI**: `gpt-4`, `gpt-3.5-turbo`
- **Hugging Face**: [`mistralai/Mistral-7B-Instruct-v0.2`](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2)

---

## ğŸ“¦ What's Next (v2 Goals)

- ğŸ” Add citation tracing / confidence scoring
- ğŸ§  Add local LLM support (e.g., llama.cpp)
- ğŸ“š Multi-document retrieval
- ğŸ“ˆ Improve prompt tuning & factuality checks

---

## ğŸ“„ License

MIT License â€” free to use and build upon.

---

## ğŸ™‹â€â™€ï¸ Letâ€™s Connect!

- ğŸ’¼ [LinkedIn](https://linkedin.com)
- ğŸ’» Open an issue or contribute!

---

_This app was built as part of my AI/NLP portfolio to showcase modern RAG pipelines and research-focused use cases._
